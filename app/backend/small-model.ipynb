{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RATFIVE/GEOMAR-DeepLearning/blob/main/app/backend/small-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SD_wFGmmIBUp"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the data from GitHub"
      ],
      "metadata": {
        "id": "HM1ePaXH9S9y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asHRi6NrW8d7",
        "outputId": "68bc4180-a70f-4273-c667-3b38bf488983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEOMAR-DeepLearning exists\n",
            "/content/GEOMAR-DeepLearning/app/backend\n",
            "Already up to date.\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2025.1.2)\n",
            "Requirement already satisfied: copernicusmarine in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.1)\n",
            "Requirement already satisfied: openmeteo_requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: retry_requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.0.0)\n",
            "Requirement already satisfied: requests_cache in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.2.1)\n",
            "Requirement already satisfied: astroquery in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.4.9.post1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2025.1)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (7.0.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.115.8)\n",
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.9.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo->-r requirements.txt (line 4)) (2.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 5)) (2025.1.31)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: boto3>=1.26 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (1.37.2)\n",
            "Requirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (8.1.8)\n",
            "Requirement already satisfied: dask>=2022 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (2024.11.2)\n",
            "Requirement already satisfied: h5netcdf<2.0.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (5.3.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (2.10.6)\n",
            "Requirement already satisfied: pystac>=1.8.3 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (1.12.2)\n",
            "Requirement already satisfied: semver>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: zarr<3.0.0,>=2.13.3 in /usr/local/lib/python3.11/dist-packages (from copernicusmarine->-r requirements.txt (line 7)) (2.18.4)\n",
            "Requirement already satisfied: openmeteo-sdk>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from openmeteo_requests->-r requirements.txt (line 8)) (1.19.0)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/dist-packages (from requests_cache->-r requirements.txt (line 10)) (25.1.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.11/dist-packages (from requests_cache->-r requirements.txt (line 10)) (24.1.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests_cache->-r requirements.txt (line 10)) (4.3.6)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.11/dist-packages (from requests_cache->-r requirements.txt (line 10)) (1.4.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.8 in /usr/local/lib/python3.11/dist-packages (from astroquery->-r requirements.txt (line 11)) (4.13.3)\n",
            "Requirement already satisfied: html5lib>=0.999 in /usr/local/lib/python3.11/dist-packages (from astroquery->-r requirements.txt (line 11)) (1.1)\n",
            "Requirement already satisfied: keyring>=15.0 in /usr/lib/python3/dist-packages (from astroquery->-r requirements.txt (line 11)) (23.5.0)\n",
            "Requirement already satisfied: pyvo>=1.5 in /usr/local/lib/python3.11/dist-packages (from astroquery->-r requirements.txt (line 11)) (1.6.1)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.11/dist-packages (from astropy->-r requirements.txt (line 13)) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.1.31.12.41.4 in /usr/local/lib/python3.11/dist-packages (from astropy->-r requirements.txt (line 13)) (0.2025.2.17.0.34.13)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from astropy->-r requirements.txt (line 13)) (6.0.2)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->-r requirements.txt (line 14)) (0.45.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->-r requirements.txt (line 14)) (4.12.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.8->astroquery->-r requirements.txt (line 11)) (2.6)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.2 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.26->copernicusmarine->-r requirements.txt (line 7)) (1.37.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.26->copernicusmarine->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.26->copernicusmarine->-r requirements.txt (line 7)) (0.11.3)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022->copernicusmarine->-r requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022->copernicusmarine->-r requirements.txt (line 7)) (2024.10.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022->copernicusmarine->-r requirements.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022->copernicusmarine->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022->copernicusmarine->-r requirements.txt (line 7)) (8.6.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from h5netcdf<2.0.0,>=1.4.0->copernicusmarine->-r requirements.txt (line 7)) (3.12.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib>=0.999->astroquery->-r requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib>=0.999->astroquery->-r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: flatbuffers==25.2.10 in /usr/local/lib/python3.11/dist-packages (from openmeteo-sdk>=1.4.0->openmeteo_requests->-r requirements.txt (line 8)) (25.2.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.1->copernicusmarine->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.1->copernicusmarine->-r requirements.txt (line 7)) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.46.0,>=0.40.0->fastapi->-r requirements.txt (line 14)) (3.7.1)\n",
            "Requirement already satisfied: asciitree in /usr/local/lib/python3.11/dist-packages (from zarr<3.0.0,>=2.13.3->copernicusmarine->-r requirements.txt (line 7)) (0.3.3)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.11/dist-packages (from zarr<3.0.0,>=2.13.3->copernicusmarine->-r requirements.txt (line 7)) (0.19)\n",
            "Requirement already satisfied: numcodecs!=0.14.0,!=0.14.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from zarr<3.0.0,>=2.13.3->copernicusmarine->-r requirements.txt (line 7)) (0.15.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi->-r requirements.txt (line 14)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.13.0->dask>=2022->copernicusmarine->-r requirements.txt (line 7)) (3.21.0)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr<3.0.0,>=2.13.3->copernicusmarine->-r requirements.txt (line 7)) (1.2.18)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask>=2022->copernicusmarine->-r requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr<3.0.0,>=2.13.3->copernicusmarine->-r requirements.txt (line 7)) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('GEOMAR-DeepLearning'):\n",
        "    print(f'GEOMAR-DeepLearning does not exist')\n",
        "    !git clone https://github.com/RATFIVE/GEOMAR-DeepLearning.git\n",
        "    %cd GEOMAR-DeepLearning/app/backend\n",
        "    !git pull\n",
        "    !pip install -r requirements.txt\n",
        "else:\n",
        "    print(f'GEOMAR-DeepLearning exists')\n",
        "    %cd GEOMAR-DeepLearning/app/backend\n",
        "    !git pull\n",
        "    !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libaries"
      ],
      "metadata": {
        "id": "PpOApovX9ZhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1E2fH33dHzxc"
      },
      "outputs": [],
      "source": [
        "# import all necessary libraries\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from sklearn import metrics\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from torch import nn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "from utils.Copernicus import AdvancedCopernicus\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "# Ignore SettingWithCopyWarning:\n",
        "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
        "\n",
        "\n",
        "\n",
        "# Display all columns\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "9rGeihqp9dLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tdbJnAxqHzxe"
      },
      "outputs": [],
      "source": [
        "START_DATE = '2025-02-01'\n",
        "END_DATE = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "OUTPUT_FILENAME = 'output.nc'\n",
        "\n",
        "BBOX= {\n",
        "    # \"min_lon\":10.038345850696412,\n",
        "    # \"max_lon\":10.365962458698567,\n",
        "    # \"min_lat\":54.27381478077755,\n",
        "    # \"max_lat\":54.52976525577923,\n",
        "\n",
        "    \"minimum_longitude\":9.85083510071235,\n",
        "    \"maximum_longitude\":10.926709174713364,\n",
        "    \"minimum_latitude\":54.25206332481298,\n",
        "    \"maximum_latitude\":54.97306793985031,\n",
        "\n",
        "    \"target_min_lon\":10.156,\n",
        "    \"target_max_lon\":10.170,\n",
        "    \"target_min_lat\":54.354,\n",
        "    \"target_max_lat\":54.365\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_js5vt3WHzxf"
      },
      "outputs": [],
      "source": [
        "copernicus = AdvancedCopernicus()\n",
        "def load_ocean_data(variables=[\"bottomT\", \"mlotst\", \"siconc\", \"sithick\", \"sla\", \"so\", \"sob\", \"thetao\", \"uo\", \"vo\", \"wo\"],\n",
        "                    minimum_longitude=BBOX[\"minimum_longitude\"],\n",
        "                    maximum_longitude=BBOX[\"maximum_longitude\"],\n",
        "                    minimum_latitude=BBOX[\"minimum_latitude\"],\n",
        "                    maximum_latitude=BBOX[\"maximum_latitude\"],\n",
        "                    delete_file=True,\n",
        "                    output_filename='output'):\n",
        "\n",
        "    output_range = maximum_longitude - minimum_longitude\n",
        "    output_filename = f'{output_filename}-{START_DATE}-{output_range}.nc'\n",
        "\n",
        "    if os.path.exists(output_filename):\n",
        "        print(f'File {output_filename} already exists')\n",
        "        return output_filename\n",
        "\n",
        "    data = copernicus.get_subset(\n",
        "        dataset_id=\"cmems_mod_bal_phy_anfc_PT1H-i\",\n",
        "        dataset_version=\"202411\",\n",
        "        variables=variables,\n",
        "        minimum_longitude=minimum_longitude,\n",
        "        maximum_longitude=maximum_longitude,\n",
        "        minimum_latitude=minimum_latitude,\n",
        "        maximum_latitude=maximum_latitude,\n",
        "        start_datetime=START_DATE,\n",
        "        end_datetime=END_DATE,\n",
        "        minimum_depth=0.5016462206840515,\n",
        "        maximum_depth=0.5016462206840515,\n",
        "        coordinates_selection_method=\"strict-inside\",\n",
        "        disable_progress_bar=False,\n",
        "        output_filename=output_filename,\n",
        "        delete_file=delete_file)\n",
        "\n",
        "    return data.to_dataframe().reset_index()\n",
        "\n",
        "training_data = load_ocean_data(\n",
        "    variables=[\"bottomT\", \"mlotst\", \"siconc\", \"sithick\", \"sla\", \"so\", \"sob\", \"thetao\", \"uo\", \"vo\", \"wo\"],\n",
        "    minimum_longitude=BBOX[\"minimum_longitude\"],\n",
        "    maximum_longitude=BBOX[\"maximum_longitude\"],\n",
        "    minimum_latitude=BBOX[\"minimum_latitude\"],\n",
        "    maximum_latitude=BBOX[\"maximum_latitude\"], delete_file=False, output_filename='training'\n",
        ")\n",
        "\n",
        "target_data = load_ocean_data(\n",
        "    variables=[\"sla\"],\n",
        "    minimum_longitude=BBOX[\"target_min_lon\"],\n",
        "    maximum_longitude=BBOX[\"target_max_lon\"],\n",
        "    minimum_latitude=BBOX[\"target_min_lat\"],\n",
        "    maximum_latitude=BBOX[\"target_max_lat\"], delete_file=False, output_filename='target'\n",
        ")\n",
        "\n",
        "\n",
        "# Check if training_data is a class str\n",
        "if isinstance(training_data, str):\n",
        "    # Read .nc file\n",
        "    training_data = xr.open_dataset(training_data).to_dataframe().reset_index()\n",
        "    print(f'Open Training Data as DataFrame')\n",
        "else:\n",
        "    print(f'Training Data is already a DataFrame')\n",
        "\n",
        "if isinstance(target_data, str):\n",
        "    # Read .nc file\n",
        "    target_data = xr.open_dataset(target_data).to_dataframe().reset_index()\n",
        "    print(f'Open Target Data as DataFrame')\n",
        "else:\n",
        "    print(f'Target Data is already a DataFrame')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgBOkK4JHzxg"
      },
      "source": [
        "## IDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwqLdP3DHzxh"
      },
      "outputs": [],
      "source": [
        "def process_df(df):\n",
        "    df = df.dropna(axis=1, how=\"all\")\n",
        "    df = df.dropna(axis=0, how=\"any\")\n",
        "    df = df[[\"time\"] + [col for col in df.columns if col != \"time\"]]\n",
        "    float_cols = df.select_dtypes(include=[\"float\"]).columns\n",
        "    df[float_cols] = df[float_cols].astype(np.float32)\n",
        "    df[\"time\"] = pd.to_datetime(df[\"time\"]).dt.tz_localize(None).dt.round(\"h\")\n",
        "    df = df.reset_index(drop=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uD2ba4fHzxi"
      },
      "outputs": [],
      "source": [
        "training_data = process_df(training_data)\n",
        "display(training_data.head(3))\n",
        "display(training_data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA7JW-X1Hzxi"
      },
      "outputs": [],
      "source": [
        "target_data = process_df(target_data)\n",
        "target_data.groupby(by=[\"time\", 'latitude', 'longitude']).mean()\n",
        "display(target_data.head(3))\n",
        "display(target_data.info())\n",
        "display(target_data['latitude'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5pbSEgVHzxi"
      },
      "outputs": [],
      "source": [
        "df_merged = pd.merge(training_data, target_data, on=\"time\", how=\"inner\", suffixes=(\"\", \"_target\"))\n",
        "display(df_merged.head(3))\n",
        "display(df_merged.info())\n",
        "display(df_merged.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zcCc2elHzxj"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2CgiHJuHzxj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for Seaborn\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Erstellen der Plot-Figur\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot der SLA-Daten\n",
        "sns.lineplot(x=df_merged[\"time\"], y=df_merged[\"sla\"], label=\"SLA\")\n",
        "\n",
        "# Plot der SLA Target-Daten\n",
        "sns.lineplot(x=df_merged[\"time\"], y=df_merged[\"sla_target\"], label=\"SLA Target\")\n",
        "\n",
        "# Achsen und Titel setzen\n",
        "plt.title(\"Sea surface height above sea levelsla [m]\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Sea Level Anomaly (SLA)\")\n",
        "\n",
        "# Legende anzeigen\n",
        "plt.legend()\n",
        "\n",
        "# Diagramm anzeigen\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8som2gfHzxj"
      },
      "source": [
        "## Stationary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnADlihRHzxk"
      },
      "outputs": [],
      "source": [
        "# df_target = df_merged[\"sla_target\"]\n",
        "\n",
        "# rolling_mean = df_target.rolling(window = 7).mean(numeric_only=True)\n",
        "# rolling_std = df_target.rolling(window = 7).std(numeric_only=True)\n",
        "# plt.plot(df_target, color = 'blue', label = 'Original')\n",
        "# plt.plot(rolling_mean, color = 'red', label = 'Rolling Mean')\n",
        "# plt.plot(rolling_std, color = 'black', label = 'Rolling Std')\n",
        "# plt.legend(loc = 'best')\n",
        "# plt.title('Rolling Mean & Rolling Standard Deviation')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EBC6SmqHzxl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "def print_df_stats(series, order):\n",
        "    x=series\n",
        "    if (order>0):\n",
        "        x=x.diff(order)[order:]\n",
        "    result = adfuller(x)\n",
        "    print('ADF Statistic: {}'.format(result[0]))\n",
        "    print('p-value: {}'.format(result[1]))\n",
        "    print('Critical Values:')\n",
        "    for key, value in result[4].items():\n",
        "        print('\\t{}: {}'.format(key, value))\n",
        "\n",
        "print_df_stats(df_target, 0)\n",
        "print_df_stats(df_target, 1)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcAAVZ3-Hzxl"
      },
      "outputs": [],
      "source": [
        "# from statsmodels.tsa.stattools import acf, pacf\n",
        "\n",
        "# diff_series=df_target.diff(2)[2:]\n",
        "\n",
        "# lag_acf=acf(diff_series, nlags=7)\n",
        "# lag_pacf=pacf(diff_series, nlags=7, method='ols')\n",
        "# plt.figure(figsize=(20,10))\n",
        "# plt.subplot(121)\n",
        "# plt.plot(lag_acf)\n",
        "# plt.axhline(y=0,linestyle='--',color='green')\n",
        "# plt.axhline(y=-1.96/np.sqrt(len(diff_series)),linestyle='--',color='green')\n",
        "# plt.axhline(y=1.96/np.sqrt(len(diff_series)),linestyle='--',color='green')\n",
        "# plt.title('Autocorrelation Function')\n",
        "# plt.subplot(122)\n",
        "# plt.plot(lag_pacf)\n",
        "# plt.axhline(y=0,linestyle='--',color='green')\n",
        "# plt.axhline(y=-1.96/np.sqrt(len(diff_series)),linestyle='--',color='green')\n",
        "# plt.axhline(y=1.96/np.sqrt(len(diff_series)),linestyle='--',color='green')\n",
        "# plt.title('Partial Autocorrelation Function')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqRRo2XWp_hl"
      },
      "outputs": [],
      "source": [
        "cols = [col for col in df_merged.columns if df_merged[col].dtype in [np.float64, np.float32]]\n",
        "cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSi4sk79n1MC"
      },
      "source": [
        "## Transform Data to 2D-Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn9cl2qln0oL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "df = df_merged.copy()\n",
        "# 1. Convert time to datetime (if not already)\n",
        "df['time'] = pd.to_datetime(df['time'])\n",
        "\n",
        "# Round latitudes and longitudes\n",
        "df['latitude'] = df['latitude']\n",
        "df['longitude'] = df['longitude']\n",
        "\n",
        "# 2. Get unique time points (hourly)\n",
        "unique_times = df['time'].dt.strftime('%Y-%m-%d %H:00:00').unique()\n",
        "\n",
        "df = df.drop(columns=[\"sla_target\", \"sla\", \"latitude_target\", \"longitude_target\"])\n",
        "target = df_merged[\"sla_target\"]\n",
        "\n",
        "display(df.head(3))\n",
        "display(df.info())\n",
        "\n",
        "print(f'Number of Unique latituds: {len(df[\"latitude\"].unique())}')\n",
        "print(f'Number of Unique longitudes: {len(df[\"longitude\"].unique())}')\n",
        "\n",
        "# 3. Create function to map lat/lon to grid coordinates\n",
        "def map_coordinates_to_grid(df):\n",
        "    # Get unique latitudes and longitudes\n",
        "    latitudes = df['latitude'].unique()\n",
        "    longitudes = df['longitude'].unique()\n",
        "\n",
        "    # Create a grid, map latitude/longitude to a 2D grid\n",
        "    latitude_map = {lat: idx for idx, lat in enumerate(latitudes)}\n",
        "    longitude_map = {lon: idx for idx, lon in enumerate(longitudes)}\n",
        "    #print(latitude_map)\n",
        "    return latitude_map, longitude_map, len(latitudes), len(longitudes)\n",
        "\n",
        "# 4. Create RGB image for each hour\n",
        "def create_image_for_time(df, latitude_map, longitude_map, img_height, img_width):\n",
        "\n",
        "\n",
        "    # get cols wich are numerical\n",
        "    cols = [col for col in df.columns if df[col].dtype in [np.float64, np.float32]]\n",
        "\n",
        "    # Remove latitude and longitude from cols\n",
        "    cols.remove('latitude')\n",
        "    cols.remove('longitude')\n",
        "    #print(cols)\n",
        "\n",
        "    # Normalize the values of uo, wo, and vo to [0, 255]\n",
        "    #scaler = MinMaxScaler((0, 255))\n",
        "    #df[cols] = scaler.fit_transform(df[cols])\n",
        "\n",
        "    # Initialize a 2D array for every feature\n",
        "    image = np.zeros((img_height, img_width, len(cols)), dtype=np.float32)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        #print(row)\n",
        "        #print(row['latitude'])\n",
        "        lat_idx = latitude_map[row['latitude']]\n",
        "        lon_idx = longitude_map[row['longitude']]\n",
        "\n",
        "        # Assign values of the cols to the corresponding pixel\n",
        "        for col in cols:\n",
        "            image[lat_idx, lon_idx, cols.index(col)] = row[col]\n",
        "\n",
        "    return image\n",
        "\n",
        "learning_data = {}\n",
        "# 5. Loop through each unique time point and create an image\n",
        "for i, time_point in tqdm(enumerate(unique_times), desc='Creating 2D-Array Data', total=len(unique_times)):\n",
        "    # Filter data for the given time\n",
        "    time_data = df[df['time'].dt.strftime('%Y-%m-%d %H:00:00') == time_point]\n",
        "\n",
        "    # Map coordinates to grid\n",
        "    latitude_map, longitude_map, img_height, img_width = map_coordinates_to_grid(time_data)\n",
        "\n",
        "    # Create RGB image for this timepoint\n",
        "    image = create_image_for_time(time_data, latitude_map, longitude_map, img_height, img_width)\n",
        "\n",
        "    learning_data[time_point] = np.array(image)\n",
        "\n",
        "    \"\"\"\n",
        "    # Save or display the image\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'Image for {time_point}')\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "    #plt.savefig(f'image_{time_point}.png')  # Save the image\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "\n",
        "    #print(image.shape)\n",
        "    if i >= 1000:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8Uqo1NawayW"
      },
      "outputs": [],
      "source": [
        "print(len(learning_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPoAazbX50sI"
      },
      "outputs": [],
      "source": [
        "learning_data = list(learning_data.values())\n",
        "learning_data = np.array(learning_data)\n",
        "print(learning_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu9OW5LJ63g0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".main",
      "language": "python",
      "name": ".main"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}